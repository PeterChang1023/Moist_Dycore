{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c93ce09-48cb-4143-ba4d-0f30c68444fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import os\n",
    "import matplotlib.cm as cm\n",
    "from scipy.interpolate import interp1d\n",
    "from EOF import EOF\n",
    "import datetime \n",
    "from scipy.interpolate import RectBivariateSpline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6767f1aa-4e8e-40ad-9fbe-ddac7b54cbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dycore import Dycore\n",
    "def read_all_var(pr_start, pr_to, pr_leap, start, end, internal_day, total_file):\n",
    "    total_pr = int((pr_to - pr_start) / pr_leap)\n",
    "    total_day = int(total_file * internal_day)\n",
    "    \n",
    "    qv_shape = (total_pr, total_day, 20, 64, 128)\n",
    "    qv_diff_shape = (total_pr, total_day, 20, 64, 128)\n",
    "    u_shape = (total_pr, total_day, 20, 64, 128)\n",
    "    v_shape = (total_pr, total_day, 20, 64, 128)\n",
    "    t_shape = (total_pr, total_day, 20, 64, 128)\n",
    "    p_shape = (total_pr, total_day, 20, 64, 128)\n",
    "    ps_shape = (total_pr, total_day, 20, 64, 128)\n",
    "    p_half_shape = (total_pr, total_day, 21, 64, 128)\n",
    "    \n",
    "    qv = np.zeros(qv_shape)\n",
    "    qv_diff = np.zeros(qv_diff_shape)\n",
    "    u = np.zeros(u_shape)\n",
    "    v = np.zeros(v_shape)\n",
    "    t = np.zeros(t_shape)\n",
    "    p = np.zeros(p_shape)\n",
    "    ps = np.zeros(ps_shape)\n",
    "    p_half = np.zeros(p_half_shape)\n",
    "    \n",
    "    a = 0\n",
    "    for pr in range(pr_start, pr_to, pr_leap):\n",
    "        k = 0\n",
    "        for day in range(start, end, internal_day):\n",
    "            print(day)\n",
    "            if pr == 8 and day == 7500:\n",
    "                print(\"PR=8, 7500day file miss\")\n",
    "            else:\n",
    "                file = f\"HSt42_{pr}/RH80_PR{pr}_20000day_startfrom_{day}day_final.dat\"\n",
    "                dycore = Dycore(file)\n",
    "                \n",
    "                start_index = k * 100\n",
    "                end_index = (k + 1) * 100\n",
    "                \n",
    "                qv[a, start_index:end_index, :, :, :] = dycore.qv\n",
    "                qv_diff[a, start_index:end_index, :, :, :] = dycore.qv_diff\n",
    "                u[a, start_index:end_index, :, :, :] = dycore.u\n",
    "                v[a, start_index:end_index, :, :, :] = dycore.v\n",
    "                t[a, start_index:end_index, :, :, :] = dycore.t\n",
    "                ps[a, start_index:end_index, :, :, :] = dycore.ps\n",
    "                p[a, start_index:end_index, :, :, :] = dycore.p\n",
    "                p_half[a, start_index:end_index, :, :, :] = dycore.p_half\n",
    "                k += 1\n",
    "        a += 1\n",
    "    return qv, qv_diff, u, v, t, p, ps, p_half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c0063d6-042b-4653-9f21-e0c8fbd5024b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "pr_start = 10\n",
    "pr_leap = 10\n",
    "pr_to = 60\n",
    "total_pr = (pr_to - pr_start) / pr_leap\n",
    "\n",
    "start = 500\n",
    "end   = 20000\n",
    "internal_day = 100\n",
    "total_day = int((end -start)/internal_day) * internal_day\n",
    "\n",
    "total_file = int((end - start) / internal_day)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c4ec222-4f44-4f85-b8fb-b4fb5df4f331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---1---\n",
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "### read variables ###\n",
    "u_file       = h5py.File(\"PR10_50_0_20000day_u.h5\", \"r\")\n",
    "# w_file       = h5py.File(\"PR10_50_0_20000day_w.h5\", \"r\")\n",
    "\n",
    "# qv_file      = h5py.File(\"PR10_50_0_20000day_qv.h5\", \"r\")\n",
    "# qv_diff_file = h5py.File(\"PR10_50_0_20000day_qv_diff.h5\", \"r\")\n",
    "# p_file       = h5py.File(\"PR10_50_0_20000day_p.h5\", \"r\")\n",
    "# ps_file      = h5py.File(\"PR10_50_0_20000day_ps.h5\", \"r\")\n",
    "# p_half_file  = h5py.File(\"PR10_50_0_20000day_p_half.h5\", \"r\")\n",
    "\n",
    "# z_full_file  = h5py.File(\"PR10_50_0_20000day_z_full.h5\", \"r\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"---1---\")\n",
    "u_origin       = np.asarray(u_file[\"u\"][:,int(start):end,:,:,:])\n",
    "# qv_origin       = np.asarray(qv_file[\"qv\"][:,int(start):end,:,:,:])\n",
    "# print(\"---2---\")\n",
    "# qv_diff_origin = np.asarray(qv_diff_file[\"qv_diff\"][:,int(start):end,:,:,:])\n",
    "# print(\"---3---\")\n",
    "# p_origin       = np.asarray(p_file[\"p\"][:,int(start):end,:,:,:])\n",
    "# print(\"---4---\")\n",
    "# ps_origin      = np.asarray(ps_file[\"ps\"][:,int(start):end,:,:,:])\n",
    "# print(\"---5---\")\n",
    "# p_half_origin  = np.asarray(p_half_file[\"p_half\"][:,int(start):end,:,:,:])\n",
    "# print(\"---6---\")\n",
    "\n",
    "# w_origin       = np.asarray(w_file[\"w\"][:,int(start):end,:,:,:])\n",
    "# z_full_origin       = np.asarray(z_full_file[\"z_full\"][:,int(start):end,:,:,:])\n",
    "\n",
    "\n",
    "print(\"done\")\n",
    "\n",
    "u_file.close()\n",
    "# qv_file.close()\n",
    "# qv_diff_file.close()\n",
    "# p_file.close()\n",
    "# ps_file.close()\n",
    "# p_half_file.close()\n",
    "# w_file.close()\n",
    "# z_full_file.close()\n",
    "\n",
    "v_file       = h5py.File(\"PR10_50_0_20000day_v.h5\", \"r\")\n",
    "v_origin       = np.asarray(v_file[\"v\"][:,int(start):end,:,:,:])\n",
    "t_file       = h5py.File(\"PR10_50_0_20000day_t.h5\", \"r\")\n",
    "t_origin       = np.asarray(t_file[\"t\"][:,int(start):end,:,:,:])\n",
    "\n",
    "v_file.close()\n",
    "t_file.close()\n",
    "\n",
    "print(\"done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eae21a9-da2a-4c00-91b4-0f0a65d76505",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = u_origin\n",
    "# qv = qv_origin\n",
    "# qv_diff = qv_diff_origin\n",
    "# p = p_origin\n",
    "# ps = ps_origin\n",
    "# p_half = p_half_origin\n",
    "# w = w_origin\n",
    "# z_full = z_full_origin\n",
    "v = v_origin\n",
    "t = t_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0795a47c-ef0f-4b48-bed4-9764ecf306dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 100, 20, 64, 128)\n"
     ]
    }
   ],
   "source": [
    "print(u.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4866e8-0785-43b6-b72f-e5016d8dd7f4",
   "metadata": {},
   "source": [
    "# time mean T for EHF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a351959-df8e-4e44-baa3-862f65675c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ttm = np.nanmean(t, axis=1)\n",
    "with h5py.File('PR10_50_500_20000day_t_time_mean.h5','w') as Ttm_file :\n",
    "    Ttm_file.create_dataset('t',data=Ttm)\n",
    "    # ps = np.asarray(ps_file[\"ps\"][:,int(start):end,:,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7874dd2-8e61-4c0e-af69-1f63b311a074",
   "metadata": {},
   "source": [
    "# time mean, zonal mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f52d09db-9e62-4009-8266-3f4adc7dc67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# u_mean = np.nanmean(u, axis=(1,4))\n",
    "# qv_mean = np.nanmean(qv, axis=(1,4))\n",
    "# qv_diff_mean = np.nanmean(qv_diff, axis=(1,4))\n",
    "# p_mean = np.nanmean(p, axis=(1,4))\n",
    "# ps_mean = np.nanmean(ps, axis=(1,4))\n",
    "# p_half_mean = np.nanmean(p_half, axis=(1,4))\n",
    "# w_mean = np.nanmean(w, axis=(1,4))\n",
    "# z_full_mean = np.nanmean(z_full, axis=(1,4))\n",
    "# v_mean = np.nanmean(v, axis=(1,4))\n",
    "# t_mean = np.nanmean(t, axis=(1,4))\n",
    "# print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d001e102-37a7-469a-b2f0-c982d9b00bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # you would get (5,20,64)\n",
    "# str = \"time_zonal_mean\"\n",
    "# with h5py.File(str+'PR10_50_0_20000day_u.h5','w') as u_file :\n",
    "#     u_file.create_dataset('u',data=u_mean)\n",
    "#     # u = np.asarray(u_file[\"u\"][:,int(start):end,:,:,:])\n",
    "\n",
    "\n",
    "# with h5py.File(str+'PR10_50_0_20000day_qv.h5','w') as qv_file :\n",
    "#     qv_file.create_dataset('qv',data=qv_mean)\n",
    "#     # qv = np.asarray(qv_file[\"qv\"][:,int(start):end,:,:,:])\n",
    "\n",
    "\n",
    "# with h5py.File(str+'PR10_50_0_20000day_qv_diff.h5','w') as qv_diff_file :\n",
    "#     qv_diff_file.create_dataset('qv_diff',data=qv_diff_mean)\n",
    "#     # qv_diff = np.asarray(qv_diff_file[\"qv_diff\"][:,int(start):end,:,:,:])\n",
    "\n",
    "\n",
    "# with h5py.File(str+'PR10_50_0_20000day_v.h5','w') as v_file :\n",
    "#     v_file.create_dataset('v',data=v_mean)\n",
    "#     # ps = np.asarray(ps_file[\"ps\"][:,int(start):end,:,:,:])\n",
    "\n",
    "\n",
    "# with h5py.File(str+'PR10_50_0_20000day_t.h5','w') as t_file :\n",
    "#     t_file.create_dataset('t',data=t_mean)\n",
    "#     # ps = np.asarray(ps_file[\"ps\"][:,int(start):end,:,:,:])\n",
    "\n",
    "\n",
    "# with h5py.File(str+'PR10_50_0_20000day_w.h5','w') as w_file :\n",
    "#     w_file.create_dataset('w',data=w_mean)\n",
    "#     # ps = np.asarray(ps_file[\"ps\"][:,int(start):end,:,:,:])\n",
    "\n",
    "# with h5py.File(str+'PR10_50_0_20000day_p.h5','w') as p_file :\n",
    "#     p_file.create_dataset('p',data=p_mean)\n",
    "#     # p = np.asarray(p_file[\"p\"][:,int(start):end,:,:,:])\n",
    "\n",
    "\n",
    "# with h5py.File(str+'PR10_50_0_20000day_ps.h5','w') as ps_file :\n",
    "#     ps_file.create_dataset('ps',data=ps_mean)\n",
    "#     # ps = np.asarray(ps_file[\"ps\"][:,int(start):end,:,:,:])\n",
    "\n",
    "\n",
    "# with h5py.File(str+'PR10_50_0_20000day_p_half.h5','w') as p_half_file :\n",
    "#     p_half_file.create_dataset('p_half',data=p_half_mean)\n",
    "#     # ps = np.asarray(ps_file[\"ps\"][:,int(start):end,:,:,:])\n",
    "\n",
    "\n",
    "# with h5py.File(str+'PR10_50_0_20000day_z_full.h5','w') as z_full_file :\n",
    "#     z_full_file.create_dataset('z_full',data=z_full_mean)\n",
    "#     # ps = np.asarray(ps_file[\"ps\"][:,int(start):end,:,:,:])\n",
    "\n",
    "# print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "802119b3-04a4-412c-a0b7-5af65c5b2b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# str = \"time_zonal_mean\"\n",
    "\n",
    "# u_test      = h5py.File(str+\"PR10_50_0_20000day_u.h5\", \"r\")\n",
    "# u_origin       = np.asarray(u_test[\"u\"][:,:,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43bfc36f-189e-4a10-a940-26366c63cbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(u_origin.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68094e5-e288-4fe9-aa82-9f30889e4e1d",
   "metadata": {},
   "source": [
    "# zonal mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1c63df8-8d1c-4733-b08b-2950b8752297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# u_mean = np.nanmean(u, axis=(4))\n",
    "# qv_mean = np.nanmean(qv, axis=(4))\n",
    "# qv_diff_mean = np.nanmean(qv_diff, axis=(4))\n",
    "# p_mean = np.nanmean(p, axis=(4))\n",
    "# ps_mean = np.nanmean(ps, axis=(4))\n",
    "# p_half_mean = np.nanmean(p_half, axis=(4))\n",
    "# w_mean = np.nanmean(w, axis=(4))\n",
    "# z_full_mean = np.nanmean(z_full, axis=(4))\n",
    "# v_mean = np.nanmean(v, axis=(4))\n",
    "# t_mean = np.nanmean(t, axis=(4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f90cfc8f-08a9-4bbf-90df-e86aaba63661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # you would get (5,20,64)\n",
    "# str = \"tmp_zonal_mean\"\n",
    "# with h5py.File(str+'PR10_50_0_10000day_u.h5','w') as u_file :\n",
    "#     u_file.create_dataset('u',data=u_mean)\n",
    "#     # u = np.asarray(u_file[\"u\"][:,int(start):end,:,:,:])\n",
    "\n",
    "\n",
    "# with h5py.File(str+'PR10_50_0_10000day_qv.h5','w') as qv_file :\n",
    "#     qv_file.create_dataset('qv',data=qv_mean)\n",
    "#     # qv = np.asarray(qv_file[\"qv\"][:,int(start):end,:,:,:])\n",
    "\n",
    "\n",
    "# with h5py.File(str+'PR10_50_0_10000day_qv_diff.h5','w') as qv_diff_file :\n",
    "#     qv_diff_file.create_dataset('qv_diff',data=qv_diff_mean)\n",
    "#     # qv_diff = np.asarray(qv_diff_file[\"qv_diff\"][:,int(start):end,:,:,:])\n",
    "\n",
    "\n",
    "# with h5py.File(str+'PR10_50_0_10000day_v.h5','w') as v_file :\n",
    "#     v_file.create_dataset('v',data=v_mean)\n",
    "#     # ps = np.asarray(ps_file[\"ps\"][:,int(start):end,:,:,:])\n",
    "\n",
    "\n",
    "# with h5py.File(str+'PR10_50_0_10000day_t.h5','w') as t_file :\n",
    "#     t_file.create_dataset('t',data=t_mean)\n",
    "#     # ps = np.asarray(ps_file[\"ps\"][:,int(start):end,:,:,:])\n",
    "\n",
    "\n",
    "# with h5py.File(str+'PR10_50_0_10000day_w.h5','w') as w_file :\n",
    "#     w_file.create_dataset('w',data=w_mean)\n",
    "#     # ps = np.asarray(ps_file[\"ps\"][:,int(start):end,:,:,:])\n",
    "\n",
    "# with h5py.File(str+'PR10_50_0_10000day_p.h5','w') as p_file :\n",
    "#     p_file.create_dataset('p',data=p_mean)\n",
    "#     # p = np.asarray(p_file[\"p\"][:,int(start):end,:,:,:])\n",
    "\n",
    "\n",
    "# with h5py.File(str+'PR10_50_0_10000day_ps.h5','w') as ps_file :\n",
    "#     ps_file.create_dataset('ps',data=ps_mean)\n",
    "#     # ps = np.asarray(ps_file[\"ps\"][:,int(start):end,:,:,:])\n",
    "\n",
    "\n",
    "# with h5py.File(str+'PR10_50_0_10000day_p_half.h5','w') as p_half_file :\n",
    "#     p_half_file.create_dataset('p_half',data=p_half_mean)\n",
    "#     # ps = np.asarray(ps_file[\"ps\"][:,int(start):end,:,:,:])\n",
    "\n",
    "\n",
    "# with h5py.File(str+'PR10_50_0_10000day_z_full.h5','w') as z_full_file :\n",
    "#     z_full_file.create_dataset('z_full',data=z_full_mean)\n",
    "#     # ps = np.asarray(ps_file[\"ps\"][:,int(start):end,:,:,:])\n",
    "\n",
    "# print(\"finally done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14d8d370-913f-4478-97c1-034bdab60a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # you would get (5,20,64)\n",
    "# str = \"tmp_zonal_mean\"\n",
    "# with h5py.File(str+'PR10_50_10000_20000day_u.h5','w') as u_file :\n",
    "#     u_file.create_dataset('u',data=u_mean)\n",
    "#     # u = np.asarray(u_file[\"u\"][:,int(start):end,:,:,:])\n",
    "\n",
    "\n",
    "# with h5py.File(str+'PR10_50_10000_20000day_qv.h5','w') as qv_file :\n",
    "#     qv_file.create_dataset('qv',data=qv_mean)\n",
    "#     # qv = np.asarray(qv_file[\"qv\"][:,int(start):end,:,:,:])\n",
    "\n",
    "\n",
    "# with h5py.File(str+'PR10_50_10000_20000day_qv_diff.h5','w') as qv_diff_file :\n",
    "#     qv_diff_file.create_dataset('qv_diff',data=qv_diff_mean)\n",
    "#     # qv_diff = np.asarray(qv_diff_file[\"qv_diff\"][:,int(start):end,:,:,:])\n",
    "\n",
    "\n",
    "# with h5py.File(str+'PR10_50_10000_20000day_v.h5','w') as v_file :\n",
    "#     v_file.create_dataset('v',data=v_mean)\n",
    "#     # ps = np.asarray(ps_file[\"ps\"][:,int(start):end,:,:,:])\n",
    "\n",
    "\n",
    "# with h5py.File(str+'PR10_50_10000_20000day_t.h5','w') as t_file :\n",
    "#     t_file.create_dataset('t',data=t_mean)\n",
    "#     # ps = np.asarray(ps_file[\"ps\"][:,int(start):end,:,:,:])\n",
    "\n",
    "\n",
    "# with h5py.File(str+'PR10_50_10000_20000day_w.h5','w') as w_file :\n",
    "#     w_file.create_dataset('w',data=w_mean)\n",
    "#     # ps = np.asarray(ps_file[\"ps\"][:,int(start):end,:,:,:])\n",
    "\n",
    "# with h5py.File(str+'PR10_50_10000_20000day_p.h5','w') as p_file :\n",
    "#     p_file.create_dataset('p',data=p_mean)\n",
    "#     # p = np.asarray(p_file[\"p\"][:,int(start):end,:,:,:])\n",
    "\n",
    "\n",
    "# with h5py.File(str+'PR10_50_10000_20000day_ps.h5','w') as ps_file :\n",
    "#     ps_file.create_dataset('ps',data=ps_mean)\n",
    "#     # ps = np.asarray(ps_file[\"ps\"][:,int(start):end,:,:,:])\n",
    "\n",
    "\n",
    "# with h5py.File(str+'PR10_50_10000_20000day_p_half.h5','w') as p_half_file :\n",
    "#     p_half_file.create_dataset('p_half',data=p_half_mean)\n",
    "#     # ps = np.asarray(ps_file[\"ps\"][:,int(start):end,:,:,:])\n",
    "\n",
    "\n",
    "# with h5py.File(str+'PR10_50_10000_20000day_z_full.h5','w') as z_full_file :\n",
    "#     z_full_file.create_dataset('z_full',data=z_full_mean)\n",
    "#     # ps = np.asarray(ps_file[\"ps\"][:,int(start):end,:,:,:])\n",
    "\n",
    "# print(\"finally done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a005fd-0b8a-42fd-b02d-51e225ed6250",
   "metadata": {},
   "source": [
    "# load test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65283169-fda0-43ef-80a8-68061180c523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# str = \"tmp_zonal_mean\"\n",
    "# u_file1      = h5py.File(str+\"PR10_50_0_10000day_u.h5\", \"r\")\n",
    "# u_file2      = h5py.File(str+\"PR10_50_10000_20000day_u.h5\", \"r\")\n",
    "\n",
    "# u1       = np.asarray(u_file1[\"u\"][:,:,:,:])\n",
    "# u2       = np.asarray(u_file2[\"u\"][:,:,:,:])\n",
    "# ####################################################################\n",
    "# v_file1      = h5py.File(str+\"PR10_50_0_10000day_v.h5\", \"r\")\n",
    "# v_file2      = h5py.File(str+\"PR10_50_10000_20000day_v.h5\", \"r\")\n",
    "\n",
    "# v1       = np.asarray(v_file1[\"v\"][:,:,:,:])\n",
    "# v2       = np.asarray(v_file2[\"v\"][:,:,:,:])\n",
    "# ####################################################################\n",
    "# t_file1      = h5py.File(str+\"PR10_50_0_10000day_t.h5\", \"r\")\n",
    "# t_file2      = h5py.File(str+\"PR10_50_10000_20000day_t.h5\", \"r\")\n",
    "\n",
    "# t1       = np.asarray(t_file1[\"t\"][:,:,:,:])\n",
    "# t2       = np.asarray(t_file2[\"t\"][:,:,:,:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "075bd9e8-6074-42a5-977b-d9e93ec42807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10000, 20, 64)\n"
     ]
    }
   ],
   "source": [
    "# print(u1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d786a401-52d3-4a5f-8194-526fcba3de23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# print(int(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccd88162-26dc-45b2-b1b1-d42222ebcb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 20000, 20, 64)\n"
     ]
    }
   ],
   "source": [
    "# Uzm = np.append(u1, u2, axis=1)\n",
    "# Vzm = np.append(v1, v2, axis=1)\n",
    "# Tzm = np.append(t1, t2, axis=1)\n",
    "\n",
    "# print(Uzm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bc47764-ea04-49e5-ab07-5a005848d370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_day = int(end-start)\n",
    "# u_prime = np.zeros(((((5, total_day, 20, 64, 128)))))\n",
    "# v_prime = np.zeros(((((5, total_day, 20, 64, 128)))))\n",
    "# t_prime = np.zeros(((((5, total_day, 20, 64, 128)))))\n",
    "\n",
    "\n",
    "# for a in range(0, 5):\n",
    "#     for j in range(total_day):\n",
    "#         for i in range(128):    \n",
    "#             u_prime[a,j,:,:,i] = u[a,j,:,:,i] - Uzm[a,int(j+start)] # np.rollaxis((np.rollaxis(u[a], 3, 0) - np.nanmean(u[a], axis=3)), 0, 4)\n",
    "#             v_prime[a,j,:,:,i] = v[a,j,:,:,i] - Vzm[a,int(j+start)] # np.rollaxis((np.rollaxis(v[a], 3, 0) - np.nanmean(v[a], axis=3)), 0, 4)\n",
    "#             t_prime[a,j,:,:,i] = t[a,j,:,:,i] - Tzm[a,int(j+start)] # np.rollaxis((np.rollaxis(t[a], 3, 0) - np.nanmean(t[a], axis=3)), 0, 4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3c3452-1d26-48f6-a70e-bb3af04bf6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with h5py.File('PR10_50_500_20000day_u_prime.h5','w') as u_prime_file :\n",
    "#     u_prime_file.create_dataset('u_prime',data=u_prime)\n",
    "\n",
    "# with h5py.File('PR10_50_500_20000day_v_prime.h5','w') as v_prime_file :\n",
    "#     v_prime_file.create_dataset('v_prime',data=v_prime)\n",
    "\n",
    "# with h5py.File('PR10_50_500_20000day_t_prime.h5','w') as t_prime_file :\n",
    "#     t_prime_file.create_dataset('t_prime',data=t_prime)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
